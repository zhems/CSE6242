{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 Using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "# Import statements run before running other code cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Read in all the data. Replace the 'xxx' with the path to the data set.\n",
    "# XXX\n",
    "\n",
    "# data = pd.read_csv('xxx')\n",
    "\n",
    "# Separate out the x_data and y_data.\n",
    "# x_data = data.loc[:, data.columns != \"y\"]\n",
    "# y_data = data.loc[:, \"y\"]\n",
    "\n",
    "# -------------------------------\n",
    "data = pd.read_csv('pulsar_stars.csv')\n",
    "\n",
    "# Separate out the x_data and y_data.\n",
    "x_data = data.loc[:, data.columns != \"y\"]\n",
    "y_data = data.loc[:, \"y\"]\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The random state to use while splitting the data.\n",
    "# random_state = 100\n",
    "\n",
    "# XXX\n",
    "# TODO: Split 70% of the data into training and 30% into test sets. Call them x_train, x_test, y_train and y_test.\n",
    "# Use the train_test_split method in sklearn with the parameter 'shuffle' set to true and the 'random_state' set to 100.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=100)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7078     0\n",
       "10660    0\n",
       "9635     0\n",
       "9144     0\n",
       "3570     0\n",
       "        ..\n",
       "16304    0\n",
       "79       0\n",
       "12119    0\n",
       "14147    0\n",
       "5640     0\n",
       "Name: y, Length: 12528, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7078</td>\n",
       "      <td>114.734375</td>\n",
       "      <td>45.543675</td>\n",
       "      <td>0.229792</td>\n",
       "      <td>0.200990</td>\n",
       "      <td>24.144649</td>\n",
       "      <td>69.262865</td>\n",
       "      <td>2.531836</td>\n",
       "      <td>4.449188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10660</td>\n",
       "      <td>109.351562</td>\n",
       "      <td>38.869893</td>\n",
       "      <td>0.168128</td>\n",
       "      <td>0.824654</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>12.436564</td>\n",
       "      <td>12.255024</td>\n",
       "      <td>189.452922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9635</td>\n",
       "      <td>106.109375</td>\n",
       "      <td>42.514930</td>\n",
       "      <td>0.537584</td>\n",
       "      <td>0.965991</td>\n",
       "      <td>2.300167</td>\n",
       "      <td>17.121229</td>\n",
       "      <td>9.246154</td>\n",
       "      <td>97.825740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9144</td>\n",
       "      <td>129.070312</td>\n",
       "      <td>51.580214</td>\n",
       "      <td>0.227924</td>\n",
       "      <td>-0.025761</td>\n",
       "      <td>5.892977</td>\n",
       "      <td>26.877934</td>\n",
       "      <td>5.328182</td>\n",
       "      <td>30.635998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3570</td>\n",
       "      <td>93.273438</td>\n",
       "      <td>51.757203</td>\n",
       "      <td>0.742549</td>\n",
       "      <td>0.474389</td>\n",
       "      <td>187.474080</td>\n",
       "      <td>60.763208</td>\n",
       "      <td>-2.269474</td>\n",
       "      <td>4.231114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16304</td>\n",
       "      <td>107.453125</td>\n",
       "      <td>52.730129</td>\n",
       "      <td>0.480646</td>\n",
       "      <td>-0.080883</td>\n",
       "      <td>196.711538</td>\n",
       "      <td>69.991086</td>\n",
       "      <td>-1.929495</td>\n",
       "      <td>2.532311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>124.500000</td>\n",
       "      <td>57.353618</td>\n",
       "      <td>-0.014849</td>\n",
       "      <td>-0.550964</td>\n",
       "      <td>4.783445</td>\n",
       "      <td>27.501640</td>\n",
       "      <td>6.090449</td>\n",
       "      <td>37.818091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12119</td>\n",
       "      <td>105.875000</td>\n",
       "      <td>41.837110</td>\n",
       "      <td>0.253195</td>\n",
       "      <td>0.400189</td>\n",
       "      <td>2.087793</td>\n",
       "      <td>16.906634</td>\n",
       "      <td>10.166011</td>\n",
       "      <td>116.735237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14147</td>\n",
       "      <td>109.906250</td>\n",
       "      <td>43.760255</td>\n",
       "      <td>0.053946</td>\n",
       "      <td>0.527836</td>\n",
       "      <td>5.914716</td>\n",
       "      <td>30.644925</td>\n",
       "      <td>5.802776</td>\n",
       "      <td>34.437668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5640</td>\n",
       "      <td>119.500000</td>\n",
       "      <td>45.219430</td>\n",
       "      <td>0.166401</td>\n",
       "      <td>0.395791</td>\n",
       "      <td>1.078595</td>\n",
       "      <td>12.914065</td>\n",
       "      <td>14.790376</td>\n",
       "      <td>241.724271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12528 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X1         X2        X3        X4          X5         X6  \\\n",
       "7078   114.734375  45.543675  0.229792  0.200990   24.144649  69.262865   \n",
       "10660  109.351562  38.869893  0.168128  0.824654    1.384615  12.436564   \n",
       "9635   106.109375  42.514930  0.537584  0.965991    2.300167  17.121229   \n",
       "9144   129.070312  51.580214  0.227924 -0.025761    5.892977  26.877934   \n",
       "3570    93.273438  51.757203  0.742549  0.474389  187.474080  60.763208   \n",
       "...           ...        ...       ...       ...         ...        ...   \n",
       "16304  107.453125  52.730129  0.480646 -0.080883  196.711538  69.991086   \n",
       "79     124.500000  57.353618 -0.014849 -0.550964    4.783445  27.501640   \n",
       "12119  105.875000  41.837110  0.253195  0.400189    2.087793  16.906634   \n",
       "14147  109.906250  43.760255  0.053946  0.527836    5.914716  30.644925   \n",
       "5640   119.500000  45.219430  0.166401  0.395791    1.078595  12.914065   \n",
       "\n",
       "              X7          X8  \n",
       "7078    2.531836    4.449188  \n",
       "10660  12.255024  189.452922  \n",
       "9635    9.246154   97.825740  \n",
       "9144    5.328182   30.635998  \n",
       "3570   -2.269474    4.231114  \n",
       "...          ...         ...  \n",
       "16304  -1.929495    2.532311  \n",
       "79      6.090449   37.818091  \n",
       "12119  10.166011  116.735237  \n",
       "14147   5.802776   34.437668  \n",
       "5640   14.790376  241.724271  \n",
       "\n",
       "[12528 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Create a LinearRegression classifier and train it.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.970705619412516"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the training set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "y_train_pred = [1 if i >=0.5 else 0 for i in reg.predict(x_train)]\n",
    "accuracy_score(y_train, y_train_pred)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9720670391061452"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the testing set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "y_test_pred = [1 if i >=0.5 else 0 for i in reg.predict(x_test)]\n",
    "accuracy_score(y_test, y_test_pred)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a RandomForestClassifier and train it.\n",
    "# WARNING: Ignore \"FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\"10 in version 0.20 to 100 in 0.22.\"\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "clf.fit(x_train, y_train) \n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9764527458492975"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the training set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "y_train_pred = clf.predict(x_train)\n",
    "accuracy_score(y_train, y_train_pred)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.978584729981378"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the test set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "y_test_pred = clf.predict(x_test)\n",
    "accuracy_score(y_test, y_test_pred)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19377698, 0.0342601 , 0.42766404, 0.15927066, 0.07075575,\n",
       "       0.0775325 , 0.02846674, 0.00827322])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Determine and print the feature importance as evaluated by the Random Forest Classifier.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "clf.feature_importances_\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 3, 5, 4, 1, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Sort them in the descending order and print the feature numbers[0 to ...].\n",
    "#       Hint: There is a direct function available in sklearn to achieve this. Also checkout argsort() function in Python.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "np.argsort(-clf.feature_importances_)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZheMin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=2,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=0,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [3, 10, 30, None],\n",
       "                         'n_estimators': [10, 30, 90, 270]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Tune the hyper-parameters 'n_estimators' and 'max_depth'.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "n_list = [10,30,90,270]\n",
    "depth_list = [3,10,30,None]\n",
    "param_grid = {\n",
    "    'n_estimators': n_list,\n",
    "    'max_depth':depth_list\n",
    "}\n",
    "clf_tuned = GridSearchCV(estimator=clf, param_grid=param_grid)\n",
    "clf_tuned.fit(x_train, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'n_estimators': 90}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print the best params, using .best_params_\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "clf_tuned.best_params_\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.979565772669221"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print the best score, using .best_score_.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "clf_tuned.best_score_\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Pre-process the data to standardize or normalize it, otherwise the grid search will take much longer.\n",
    "# Warning: Ignore \"FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning\"\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a SVC classifier and train it.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "svm = SVC(gamma='auto')\n",
    "svm.fit(x_train_scaled, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.978448275862069"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the training set using the accuracy_score method.\n",
    "# XXX\n",
    "# WARNING: Ignore \"FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\"\"\n",
    "\n",
    "# -------------------------------\n",
    "y_train_pred = svm.predict(x_train_scaled)\n",
    "accuracy_score(y_train, y_train_pred)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797020484171323"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the test set using the accuracy_score method.\n",
    "# XXX\n",
    "# WARNING: Ignore \"FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\"\"\n",
    "\n",
    "# -------------------------------\n",
    "y_test_pred = svm.predict(x_test_scaled)\n",
    "accuracy_score(y_test, y_test_pred)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZheMin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 0.3, 1.0, 3.0, 10.0],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Tune the hyper-parameters 'C' and 'kernel' (use rbf and linear).\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "svm = SVC(gamma='auto')\n",
    "C_list = [0.1,0.3,1.0,3.0,10.0]\n",
    "kernel_list = ['linear','rbf']\n",
    "param_grid = {\n",
    "    'C': C_list,\n",
    "    'kernel':kernel_list\n",
    "}\n",
    "svm_tuned = GridSearchCV(estimator=svm, param_grid=param_grid)\n",
    "svm_tuned.fit(x_train_scaled, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.979007024265645"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print the best score, using .best_score_.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "svm_tuned.best_score_\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9806034482758621\n",
      "test accuracy: 0.9813780260707635\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the training and test set accuracy values after hyperparameter tuning.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "y_train_pred = svm_tuned.predict(x_train_scaled)\n",
    "y_test_pred = svm_tuned.predict(x_test_scaled)\n",
    "# print(\"training accuracy:\",accuracy_score(y_train, y_train_pred))\n",
    "# print(\"test accuracy:\",accuracy_score(y_test, y_test_pred))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9806034482758621\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the training set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "print(accuracy_score(y_train, y_train_pred))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9813780260707635\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the testing set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "print(accuracy_score(y_test, y_test_pred))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_kernel', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Calculate the rank test score, mean testing score and mean fit time for the \n",
    "# best combination of hyperparameter values that you obtained in Q3.2. The GridSearchCV \n",
    "# class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "res = svm_tuned.cv_results_\n",
    "idx = svm_tuned.best_index_\n",
    "res.keys()\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print the rank test score for the best combination of hyperparameter values that you obtained in Q3.2. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "res['rank_test_score'][idx]\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.979007024265645"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print mean testing score for the best combination of hyperparameter values that you obtained in Q3.2. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "res['mean_test_score'][idx]\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18315466245015463"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print mean fit time for the best combination of hyperparameter values that you obtained in Q3.2. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "res['mean_fit_time'][idx]\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
       "    svd_solver='full', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Perform dimensionality reduction of the data using PCA.\n",
    "#       Set parameters n_component to 8 and svd_solver to 'full'. Keep other parameters at their default value.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "pca = PCA(n_components=8, svd_solver = 'full')\n",
    "pca.fit(x_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.71054855e-01, 7.80404050e-02, 4.12747422e-02, 6.15520409e-03,\n",
       "       2.45425694e-03, 9.78533643e-04, 3.91429289e-05, 2.85984066e-06])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Print Percentage of variance explained by each of the selected components\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "pca.explained_variance_ratio_\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11992.97512747,  3589.74779466,  2610.63625426,  1008.15059028,\n",
       "         636.59642313,   401.9685368 ,    80.39533321,    21.73076915])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: The singular values corresponding to each of the selected components.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "pca.singular_values_\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
